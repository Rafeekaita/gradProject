{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import serial\n",
    "import time\n",
    "\n",
    "# Load YOLOv4-tiny model\n",
    "model = cv2.dnn.readNetFromDarknet('yolov4-tiny.cfg', 'yolov4-tiny.weights')\n",
    "model.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)\n",
    "model.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA)\n",
    "\n",
    "# Get the output layer names\n",
    "layer_names = model.getLayerNames()\n",
    "output_layers = [layer_names[i - 1] for i in model.getUnconnectedOutLayers()]\n",
    "\n",
    "# Load the class names from the coco.names file\n",
    "with open('coco.names.txt', 'r') as f:\n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "# Open the webcam\n",
    "#droidcam_ip = 'http://172.20.10.2:4747/video'\n",
    "# Connect to Droidcam\n",
    "#cap = cv2.VideoCapture(droidcam_ip)\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "\n",
    "# Set up serial communication\n",
    "ser = serial.Serial(\"COM4\", 9600)\n",
    "\n",
    "\n",
    "def sendCommand(command):\n",
    "    ser.write(command.encode('ascii'))\n",
    "    time.sleep(0.1)\n",
    "\n",
    "\n",
    "while True:\n",
    "    # Read a frame from the webcam\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # (the rest of the code remains unchanged)\n",
    "    # Resize the frame to a size divisible by the network's stride\n",
    "    net_input_size = (416, 416)  # the network's input size\n",
    "    stride = 32  # the network's stride\n",
    "    height, width, _ = frame.shape\n",
    "    new_height = (height // stride) * stride\n",
    "    new_width = (width // stride) * stride\n",
    "    resized_frame = cv2.resize(frame, (new_width, new_height))\n",
    "\n",
    "    # Preprocess the input frame\n",
    "    blob = cv2.dnn.blobFromImage(\n",
    "        resized_frame, 1 / 255.0, net_input_size, swapRB=True, crop=False)\n",
    "\n",
    "    # Set the input to the network and run a forward pass\n",
    "    model.setInput(blob)\n",
    "    layer_outputs = model.forward(output_layers)\n",
    "\n",
    "    # Postprocess the outputs\n",
    "    boxes = []\n",
    "    confidences = []\n",
    "    class_ids = []\n",
    "    for output in layer_outputs:\n",
    "        for detection in output:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "            if confidence > 0.5:\n",
    "                center_x = int(detection[0] * width)\n",
    "                center_y = int(detection[1] * height)\n",
    "                w = int(detection[2] * width)\n",
    "                h = int(detection[3] * height)\n",
    "                x = int(center_x - w / 2)\n",
    "                y = int(center_y - h / 2)\n",
    "                boxes.append([x, y, w, h])\n",
    "                confidences.append(float(confidence))\n",
    "                class_ids.append(class_id)\n",
    "\n",
    "    # Apply non-maximum suppression to remove overlapping boxes\n",
    "    indexes = cv2.dnn.NMSBoxes(\n",
    "        boxes, confidences, score_threshold=0.5, nms_threshold=0.4)\n",
    "\n",
    "    # Draw the bounding boxes and labels\n",
    "    font = cv2.FONT_HERSHEY_PLAIN\n",
    "    colors = np.random.uniform(0, 255, size=(len(boxes), 3))\n",
    "    person_detected = False\n",
    "    for i in range(len(boxes)):\n",
    "        if i in indexes:\n",
    "            x, y, w, h = boxes[i]\n",
    "            color = colors[i]\n",
    "            class_id = class_ids[i]\n",
    "            label = str(classes[class_id])\n",
    "            if class_id == 0:  # Person is detected\n",
    "                person_detected = True\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)\n",
    "            cv2.putText(frame, label, (x, y - 5), font, 1, color, 2)\n",
    "\n",
    "    #Show the output\n",
    "    cv2.imshow('Webcam', frame)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "    # Send command to Arduino based on person detectioqqn\n",
    "        # Send command to Arduino based on person detection\n",
    "    if person_detected:\n",
    "        sendCommand('S')  # Stop\n",
    "        ser.reset_input_buffer()\n",
    "    else:\n",
    "        sendCommand('F')  # Forward\n",
    "        ser.reset_input_buffer()\n",
    "\n",
    "# Release the resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "ser.close()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
